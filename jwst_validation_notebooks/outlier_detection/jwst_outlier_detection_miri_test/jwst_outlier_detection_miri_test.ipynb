{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Notebook: outlier_detection with MIRI\n",
    "\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: FGS, MIRI, NIRCam, NIRISS, NIRSpec \n",
    "\n",
    "Tested on MIRI Simulated data\n",
    "\n",
    "### Table of Contents\n",
    "<div style=\"text-align: left\"> \n",
    "\n",
    "<br>  [Introduction](#intro_ID) <br> [Imports](#imports_ID) <br> [Set up association files](#associations_ID) <br> [Insert outliers](#outliers_ID) <br> [Run Pipeline](#pipeline_ID) <br> [Check Results](#output_ID) <br> [About This Notebook](#about_ID) <br>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro_ID\"></a>\n",
    "## Introduction\n",
    "\n",
    "This notebook processes an image through calwebb_image2 and calwebb_image3 (calwebb_detector1 is optional) and examines the output table of the source_catalog step. The steps are as follow:\n",
    "\n",
    "1) Set up data path and image list file.\n",
    "\n",
    "2) Set up association files.\n",
    "\n",
    "3) Create outlier pixels in input images.\n",
    "\n",
    "4) Run outlier_detection step in calwebb_image3. \n",
    "\n",
    "6) Compare before and after DQ values of outlier pixels\n",
    "\n",
    "These steps are set up with simulated MIRI images.\n",
    "\n",
    "The pipeline documentation for this step can be found here: https://jwst-pipeline.readthedocs.io/en/latest/jwst/outlier_detection/main.html\n",
    "\n",
    "The pipeline code is available on GitHub: https://github.com/spacetelescope/jwst\n",
    "\n",
    "Author: T. Temim (some parts adopted from the test_outlier_detection.py code for NIRCam)\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "data_dir = TemporaryDirectory()\n",
    "os.chdir(data_dir.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports_ID\"></a>\n",
    "### Set up import statements\n",
    "\n",
    "The following packages are needed to enable this notebook to run:\n",
    "* astropy for coordinate handling and calculations\n",
    "* jwst to run the pipeline steps and create associations\n",
    "* matplotlib for plotting\n",
    "* ci_watson for retrieving data from artifactory\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import json\n",
    "import jwst\n",
    "from astropy.io import fits, ascii\n",
    "from astropy.coordinates import Angle\n",
    "from astropy.table import Table, vstack, unique\n",
    "from astropy.stats import sigma_clip\n",
    "from jwst.pipeline import calwebb_image3\n",
    "from jwst.associations import asn_from_list\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base\n",
    "from jwst.outlier_detection import outlier_detection\n",
    "from ci_watson.artifactory_helpers import get_bigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "import os\n",
    "os.environ['CRDS_PATH']='$HOME/crds_cache'\n",
    "os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n",
    "os.environ['CRDS_CONTEXT']='jwst_0619.pmap'\n",
    "os.environ['TEST_BIGDATA']='https://bytesalad.stsci.edu/artifactory/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print pipeline version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jwst.__version__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve data from Artifactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file1 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'outlier_detection',\n",
    "                     'outlier_detection_miri_test', \n",
    "                     'det_image_seq1_MIRIMAGE_F560Wexp1_cal.fits')\n",
    "input_file2 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'outlier_detection',\n",
    "                     'outlier_detection_miri_test', \n",
    "                     'det_image_seq2_MIRIMAGE_F560Wexp1_cal.fits')\n",
    "input_file3 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'outlier_detection',\n",
    "                     'outlier_detection_miri_test', \n",
    "                     'det_image_seq3_MIRIMAGE_F560Wexp1_cal.fits')\n",
    "input_file4 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'outlier_detection',\n",
    "                     'outlier_detection_miri_test', \n",
    "                     'det_image_seq4_MIRIMAGE_F560Wexp1_cal.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_names=[]\n",
    "input_file_names=[input_file1,input_file2,input_file3,input_file4]\n",
    "\n",
    "imlist1=['det_image_seq1_MIRIMAGE_F560Wexp1_cal.fits','det_image_seq2_MIRIMAGE_F560Wexp1_cal.fits','det_image_seq3_MIRIMAGE_F560Wexp1_cal.fits','det_image_seq4_MIRIMAGE_F560Wexp1_cal.fits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"associations_ID\"></a>\n",
    "### Set up association files\n",
    "The level three pipeline relies on an association file to specify which files are to be combined and provide the output file name.\n",
    "\n",
    "The level two pipeline can take individual images or an association file as input. The cell below sets up association files for both level2 and level3 files.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use asn_from_list to create association table\n",
    "cal_list=imlist1\n",
    "asn = asn_from_list.asn_from_list(cal_list, rule=DMS_Level3_Base, product_name='outlier_combined.fits')\n",
    "\n",
    "# use this if you need to add non'science' exposure types\n",
    "#asn['products'][0]['members'][1]['exptype'] = 'background'\n",
    "#asn['products'][0]['members'][2]['exptype'] = 'sourcecat'\n",
    "\n",
    "# dump association table to a .json file for use in image3\n",
    "with open('outlier_asnfile.json', 'w') as fp:\n",
    "    fp.write(asn.dump()[1])\n",
    "\n",
    "outlier_json_file='outlier_asnfile.json'\n",
    "    \n",
    "json_file = outlier_json_file\n",
    "file_list = []\n",
    "file_list2 = []\n",
    "with open(json_file) as json_data:\n",
    "    d = json.load(json_data)\n",
    "    members = d['products'][0]['members']\n",
    "    for item in np.arange(0,len(members)):\n",
    "        file_list.append(members[item]['expname'])\n",
    "        file_list2.append(members[item]['expname'][:-5]+\"_outlier.fits\")\n",
    "\n",
    "    \n",
    "asn2 = asn_from_list.asn_from_list(file_list2, rule=DMS_Level3_Base, product_name='outlier_combined2.fits')\n",
    "\n",
    "# use this if you need to add non'science' exposure types\n",
    "#asn['products'][0]['members'][1]['exptype'] = 'background'\n",
    "#asn['products'][0]['members'][2]['exptype'] = 'sourcecat'\n",
    "\n",
    "# dump association table to a .json file for use in image3\n",
    "with open('outlier_asnfile2.json', 'w') as fp:\n",
    "    fp.write(asn2.dump()[1])\n",
    "    \n",
    "outlier_json_file2='outlier_asnfile2.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"outliers_ID\"></a>\n",
    "## Insert outliers \n",
    "\n",
    "Insert outliers into the data to see if they are detected in the output of the step.\n",
    "\n",
    "### Choose random pixels to produce outliers\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixloc = []\n",
    "for i in range(len(file_list)):\n",
    "    pixloc.append([random.randint(20,1010),random.randint(430,1010)])\n",
    "    pixloc.append([random.randint(20,1010),random.randint(430,1010)])\n",
    "    pixloc.append([random.randint(20,1010),random.randint(430,1010)])\n",
    "    pixloc.append([random.randint(20,1010),random.randint(430,1010)])\n",
    "pixloc2 = np.array(pixloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign values to outlier pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {}\n",
    "for i in range(len(file_list)):\n",
    "     with fits.open(input_file_names[i]) as h:\n",
    "        j = 4*i\n",
    "        med = np.median(h['SCI'].data)\n",
    "        h['SCI'].data[:,:] = 1.0   # this line should eventually be commented out (only used as a test)\n",
    "        h['SCI'].data[pixloc2[j,0],pixloc2[j,1]] = med*3.0\n",
    "        h['SCI'].data[pixloc2[j+1,0],pixloc2[j+1,1]] = med*5.0\n",
    "        h['SCI'].data[pixloc2[j+2,0],pixloc2[j+2,1]] = med*10.0\n",
    "        h['SCI'].data[pixloc2[j+3,0],pixloc2[j+3,1]] = med*20.0\n",
    "        h['DQ'].data[:,:] = 0\n",
    "        h.writeto(file_list2[i],overwrite=True)\n",
    "        images[\"img{0}\".format(i)]=h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro_ID\"></a>\n",
    "### Run outlier_detection step in calwebb_image3\n",
    "The pipeline can be set to skip steps that are not needed or in this case, are not being tested.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im3 = calwebb_image3.Image3Pipeline()\n",
    "im3.tweakreg.skip = True\n",
    "im3.source_catalog.skip = True\n",
    "im3.resample.skip = True\n",
    "im3.skymatch.skip = True\n",
    "im3.save_results=True\n",
    "#im3.resample.blendheaders = False\n",
    "#im3.outlier_detection.save_intermediate_results = True\n",
    "im3.run(outlier_json_file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"output_ID\"></a>\n",
    "## Check results\n",
    "\n",
    "### Get filenames and outlier detection outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = []\n",
    "input_files = []\n",
    "with open(outlier_json_file) as json_data:\n",
    "    d = json.load(json_data)\n",
    "    members = d['products'][0]['members']\n",
    "for item in np.arange(0,len(members)):\n",
    "    expname = members[item]['expname'][:-5]+\"_outlier.fits\"\n",
    "    expname2 = members[item]['expname'][:-5]+\"_outlier_a3001_crf.fits\"\n",
    "    input_files.append(expname)\n",
    "    output_files.append(expname2)\n",
    "    output_files.sort()\n",
    "\n",
    "all_out_dqs = []\n",
    "dq_before = []\n",
    "dq_after = []    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the before DQ pixel values (should be 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(file_list)):\n",
    "    with fits.open(input_files[i]) as h:\n",
    "        j = 4*i\n",
    "        dq_before.append([pixloc2[j,:],h['DQ'].data[pixloc2[j,0],pixloc2[j,1]]])\n",
    "        dq_before.append([pixloc2[j+1,:],h['DQ'].data[pixloc2[j+1,0],pixloc2[j+1,1]]])\n",
    "        dq_before.append([pixloc2[j+2,:],h['DQ'].data[pixloc2[j+2,0],pixloc2[j+2,1]]])\n",
    "        dq_before.append([pixloc2[j+3,:],h['DQ'].data[pixloc2[j+3,0],pixloc2[j+3,1]]])\n",
    "            \n",
    "    if save_figs == True:\n",
    "                    \n",
    "        # save figure of input dq vals\n",
    "        fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "        plt.ylabel('y pixels',fontsize=15)\n",
    "        plt.xlabel('x pixels',fontsize=15)\n",
    "        plt.imshow((h['DQ'].data == 4.0), vmin=0, vmax=1, cmap=plt.cm.gray, origin='lower')\n",
    "        ax.set_title(\"DQ Input\"+str(i),fontsize=15)\n",
    "        plt.colorbar(orientation='horizontal',pad=0.09)\n",
    "        plt.savefig(outlier_json_file[:5]+str(i)+\"_inputDQ.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the after DQ pixel values(should be 17.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(file_list)):\n",
    "    with fits.open(output_files[i]) as h:\n",
    "        j = 4*i\n",
    "        dq_after.append([pixloc2[j,:],h['DQ'].data[pixloc2[j,0],pixloc2[j,1]]])\n",
    "        dq_after.append([pixloc2[j+1,:],h['DQ'].data[pixloc2[j+1,0],pixloc2[j+1,1]]])\n",
    "        dq_after.append([pixloc2[j+2,:],h['DQ'].data[pixloc2[j+2,0],pixloc2[j+2,1]]])\n",
    "        dq_after.append([pixloc2[j+3,:],h['DQ'].data[pixloc2[j+3,0],pixloc2[j+3,1]]])\n",
    "        all_out_dqs.append((h['DQ'].data[pixloc2[j,0],pixloc2[j,1]] == 17.0))\n",
    "        all_out_dqs.append((h['DQ'].data[pixloc2[j+1,0],pixloc2[j+1,1]] == 17.0))\n",
    "        all_out_dqs.append((h['DQ'].data[pixloc2[j+2,0],pixloc2[j+2,1]] == 17.0))\n",
    "        all_out_dqs.append((h['DQ'].data[pixloc2[j+3,0],pixloc2[j+3,1]] == 17.0))\n",
    "                \n",
    "    if save_figs == True:\n",
    "                    \n",
    "        # save figure of output dq values\n",
    "        fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "        plt.ylabel('y pixels',fontsize=15)\n",
    "        plt.xlabel('x pixels',fontsize=15)\n",
    "        plt.imshow((h['DQ'].data == 4.0), vmin=0, vmax=1, cmap=plt.cm.gray, origin='lower')\n",
    "        ax.set_title(\"DQ Output\"+str(i),fontsize=15)\n",
    "        plt.colorbar(orientation='horizontal',pad=0.09)\n",
    "        plt.savefig(outlier_json_file[:5]+str(i)+\"_outputDQ.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if outlier_detection Pytest passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Output DQ values: ',all_out_dqs)\n",
    "assert np.alltrue(all_out_dqs) == True\n",
    "print('MIRI Outlier Detetion Pytest: Passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Author:** Tea Temim\n",
    "<br>**Updated On:** 08/06/20 to add in documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
