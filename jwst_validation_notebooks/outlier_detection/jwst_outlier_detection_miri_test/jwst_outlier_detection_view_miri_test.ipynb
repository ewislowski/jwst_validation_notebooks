{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Notebook: MIRI view outlier_detection\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: e.g., FGS, MIRI, NIRCam, NIRISS\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "\n",
    "<div style=\"text-align: left\"> \n",
    "    \n",
    "<br> [Introduction](#intro)\n",
    "<br> [JWST CalWG Algorithm](#algorithm)\n",
    "<br> [Defining Terms](#terms)\n",
    "<br> [Test Description](#description)\n",
    "<br> [Data Description](#data_descr)\n",
    "<br> [Imports](#imports)\n",
    "<br> [Loading the Data](#data_load)\n",
    "<br> [Run the Pipeline](#pipeline)\n",
    "<br> [Perform Tests or Visualization](#testing) \n",
    "<br> [About This Notebook](#about)\n",
    "<br>    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# Introduction\n",
    "\n",
    "This notebook allows visual inspection of a set of dithered images that are combined as part of calwebb_image3. The notebook will take a set of eight simulated images, starting with the uncal format files that are the output of MIRISim. These images will have a randomized location for about 50 point sources and no extended sources.\n",
    "\n",
    "These data files will be processed through calwebb_detector1, calwebb_image2 and calwebb_image3 and the output *i2d data file will be inspected. Past versions of the pipeline had the background subtracted twice, so the background levels were strongly negative, and other versions have had the background pixels wrongly flagged by outlier_detection. This notebook is simply a visual inspection to be sure there is nothing obviously wrong with the output. While this notebook will look at the output of calwebb_image3 as a whole, the main task is to find where outlier_detection is incorrectly flagging pixels.\n",
    "\n",
    "> Pipeline documentation: https://jwst-pipeline.readthedocs.io/en/latest/jwst/outlier_detection/main.html\n",
    "\n",
    "> Pipeline code: https://github.com/spacetelescope/jwst/tree/master/jwst/outlier_detection\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"algorithm\"></a>\n",
    "# JWST CalWG Algorithm\n",
    "\n",
    "The outlier detection algorithm is defined in the confluence page listed here. It is used to reject outlier pixels found when comparing multiple dithered images together. Images are compared in overlapping regions and any pixel that seems to be an outlier (based on iterative sigma clipping) can be flagged and rejected from any combined set or mosaic of images.\n",
    "\n",
    "> https://outerspace.stsci.edu/display/JWSTCC/Vanilla+Outlier+Detection\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"terms\"></a>\n",
    "# Defining Terms\n",
    "\n",
    "Here are some of the terms that will be used in this notebook.\n",
    "\n",
    "JWST: James Webb Space Telescope\n",
    "\n",
    "MIRI: Mid-Infrafred Instrument\n",
    "\n",
    "MIRISim: MIRI data simulator\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"description\"></a>\n",
    "# Test Description\n",
    "\n",
    "This test takes a set of simulated images (at different dithered positions) and proceses them through all three stages of the Imager pipeline: calwebb_detector1, calwebb_image2, and calwebb_image3. The tests being run here look at the output of the full image3 pipeine (the combined i2d data), check that the source_catalog output catalog marks the locations of our point sources, and checks on the number of pixels that are flagged in the outlier_detection step to be sure that the step is not flagging too many pixels.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_descr\"></a>\n",
    "# Data Description\n",
    "\n",
    "The set of data used in this particular test were created with the MIRI Data Simulator (MIRISim). The simulator created eight imaging mode files, two exposures each at four different dither positions, using the specified filter. There are approximately 50 point sources scattered through the images.\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tempdir\"></a>\n",
    "# Set up Temporary Directory\n",
    "The following cell sets up a temporary directory (using python's `tempfile.TemporaryDirectory()`), and changes the script's active directory into that directory (using python's `os.chdir()`). This is so that, when the notebook is run through, it will download files to (and create output files in) the temporary directory rather than in the notebook's directory. This makes cleanup significantly easier (since all output files are deleted when the notebook is shut down), and also means that different notebooks in the same directory won't interfere with each other when run by the automated webpage generation process.\n",
    "\n",
    "If you want the notebook to generate output in the notebook's directory, simply don't run this cell.\n",
    "\n",
    "If you have a file (or files) that are kept in the notebook's directory, and that the notebook needs to use while running, you can copy that file into the directory (the code to do so is present below, but commented out).\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "import shutil\n",
    "data_dir = TemporaryDirectory()\n",
    "\n",
    "# If you have files that are in the notebook's directory, but that the notebook will need to use while\n",
    "# running, copy them into the temporary directory here.\n",
    "#\n",
    "# files = ['name_of_file']\n",
    "# for file_name in files:\n",
    "#     shutil.copy(file_name, os.path.join(data_dir.name, file_name))\n",
    "\n",
    "os.chdir(data_dir.name)\n",
    "print(data_dir.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports\"></a>\n",
    "# Imports\n",
    "List the package imports and why they are relevant to this notebook.\n",
    "\n",
    "\n",
    "* astropy.io for opening fits files\n",
    "* astropy visualization for viewing images\n",
    "* jwst pipeline to get the pipeline stages being tested\n",
    "* jwst.datamodels for building model for JWST Pipeline\n",
    "* ci_watson tools to retrieve data from artifactory\n",
    "* matplotlib.pyplot.plt to generate plots\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.visualization import LogStretch, PercentileInterval, ManualInterval, LinearStretch\n",
    "from astropy import table\n",
    "from astropy.visualization import (MinMaxInterval, SqrtStretch,\n",
    "                                   ImageNormalize)\n",
    "\n",
    "from ci_watson.artifactory_helpers import get_bigdata\n",
    "import glob\n",
    "\n",
    "from jwst.pipeline import Detector1Pipeline, Image2Pipeline, Image3Pipeline\n",
    "from jwst import associations\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base\n",
    "from jwst.associations import asn_from_list\n",
    "from jwst.datamodels import RampModel, ImageModel, dqflags\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_load\"></a>\n",
    "# Loading the Data\n",
    "\n",
    "### Data for internal use: Artifactory method\n",
    "Artifactory should be used for data that is for internal use only.\n",
    "\n",
    "The MIRISim data and any needed reference files to use with this simulated data are stored in artifactory.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading input file 1\")\n",
    "input_file1 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'outlier_detection',\n",
    "                     'outlier_detection_miri_test', \n",
    "                     'starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp1.fits')\n",
    "print(\"Downloading input file 2\")\n",
    "input_file2 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'outlier_detection',\n",
    "                     'outlier_detection_miri_test', \n",
    "                     'starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp2.fits')\n",
    "print(\"Downloading input file 3\")\n",
    "input_file3 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'outlier_detection',\n",
    "                     'outlier_detection_miri_test', \n",
    "                     'starfield_50star4ptdither_seq2_MIRIMAGE_F1130Wexp1.fits')\n",
    "print(\"Downloading input file 4\")\n",
    "input_file4 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'outlier_detection',\n",
    "                     'outlier_detection_miri_test', \n",
    "                     'starfield_50star4ptdither_seq2_MIRIMAGE_F1130Wexp2.fits')\n",
    "print(\"Downloading input file 5\")\n",
    "input_file5 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'outlier_detection',\n",
    "                     'outlier_detection_miri_test', \n",
    "                     'starfield_50star4ptdither_seq3_MIRIMAGE_F1130Wexp1.fits')\n",
    "print(\"Downloading input file 6\")\n",
    "input_file6 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'outlier_detection',\n",
    "                     'outlier_detection_miri_test', \n",
    "                     'starfield_50star4ptdither_seq3_MIRIMAGE_F1130Wexp2.fits')\n",
    "print(\"Downloading input file 7\")\n",
    "input_file7 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'outlier_detection',\n",
    "                     'outlier_detection_miri_test', \n",
    "                     'starfield_50star4ptdither_seq4_MIRIMAGE_F1130Wexp1.fits')\n",
    "print(\"Downloading input file 8\")\n",
    "input_file8 = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'outlier_detection',\n",
    "                     'outlier_detection_miri_test', \n",
    "                     'starfield_50star4ptdither_seq4_MIRIMAGE_F1130Wexp2.fits')\n",
    "\n",
    "#This readnoise file is needed for use with simulated data which has higher readnoise than actual data.\n",
    "readnoise = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'jump',                     \n",
    "                     'jump_miri_test', \n",
    "                     'jwst_mirisim_readnoise.fits')\n",
    "\n",
    "\n",
    "print(\"Finished Downloads\")\n",
    "input_files=[input_file1,input_file2,input_file3,input_file4,input_file5,input_file6,input_file7,input_file8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline\"></a>\n",
    "# Run the Steps or Pipeline\n",
    "\n",
    "The sections below will run the data through multiple pipeline steps.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the calwebb_detector1 pipeline\n",
    "\n",
    "# set up pipeline parameters \n",
    "rej_thresh=10.0  # rejection threshold for jump step\n",
    "\n",
    "print('There are ', len(input_files), ' images.')\n",
    "    \n",
    "# set up pipeline parameters for input\n",
    "pipe1 = Detector1Pipeline()\n",
    "pipe1.jump.rejection_threshold = rej_thresh\n",
    "pipe1.jump.override_readnoise = readnoise\n",
    "pipe1.ramp_fit.override_readnoise = readnoise\n",
    "\n",
    "pipe1.refpix.skip = True  # needs update to simulator for this to work properly with simulated data\n",
    "    \n",
    "slopelist = []    \n",
    "    \n",
    "# loop over list of files\n",
    "for file in input_files:\n",
    "       \n",
    "    # set up output file name\n",
    "    base, remainder = file.split('.')\n",
    "    outname = base\n",
    "        \n",
    "    pipe1.jump.output_file = outname+'.fits'    \n",
    "    #pipe1.ramp_fit.output_file = outname+'.fits'\n",
    "    pipe1.output_file = outname+'.fits'\n",
    "\n",
    "    # Run pipeline on each file\n",
    "    rampfile = pipe1.run(file)\n",
    "    slopelist.append(rampfile)\n",
    "    \n",
    "    # Close the input files\n",
    "    #file.close()\n",
    "\n",
    "print('Detector 1 steps completed on all files.')\n",
    "print(slopelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Calwebb_image2 on output files from detector1\n",
    "    \n",
    "print('There are ', len(slopelist), ' images.')\n",
    "    \n",
    "\n",
    "# create an object for the pipeline    \n",
    "pipe2 = Image2Pipeline()\n",
    "\n",
    "callist = []\n",
    "\n",
    "# cycle through files\n",
    "for rampfile in slopelist:\n",
    "    filename = rampfile.meta.filename\n",
    "    # Set pipeline parameters\n",
    "\n",
    "    pipe2.save_results = True\n",
    "    pipe2.output_file = filename +'_cal.fits'\n",
    "    pipe2.resample.save_results = True\n",
    "    pipe2.suffix = None\n",
    "\n",
    "    calfile = pipe2.run(rampfile)\n",
    "\n",
    "    callist.append(calfile)\n",
    "\n",
    "print(callist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create association table of data output from calwebb_image2.\n",
    "\n",
    "The calwebb_image3 pipeline takes in an association table of a set of images which should be combined. The association table can also be used to specify a background image to be subtracted or a source catalog to be used within the pipeline (sourcecat is not typically used with MIRI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use asn_from_list to create association table\n",
    "import glob\n",
    "calfiles = glob.glob('starfield*_cal.fits')\n",
    "asn = asn_from_list.asn_from_list(calfiles, rule=DMS_Level3_Base, product_name='starfield_50star4ptdither_combined.fits')\n",
    "\n",
    "# use this if you need to add non'science' exposure types\n",
    "#asn['products'][0]['members'][1]['exptype'] = 'background'\n",
    "#asn['products'][0]['members'][2]['exptype'] = 'sourcecat'\n",
    "\n",
    "# dump association table to a .json file for use in image3\n",
    "with open('starfield_50star4ptdither_asnfile.json', 'w') as fp:\n",
    "    fp.write(asn.dump()[1])\n",
    "\n",
    "print(asn)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run calwebb_image3 on the association table, setting any specific parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use association table created in previous step with calwebb_image3\n",
    "    \n",
    "# set any specific parameters\n",
    "# tweakreg parameters to allow data to run\n",
    "fwhm=3.762  # Gaussian kernel FWHM of objects expected, default=2.5\n",
    "minobj=5  # minimum number of objects needed to match positions for a good fit, default=15\n",
    "snr= 250 # signal to noise threshold, default=5\n",
    "sigma= 3 # clipping limit, in sigma units, used when performing fit, default=3\n",
    "fit_geom='shift' # ftype of affine transformation to be considered when fitting catalogs, default='general'\n",
    "use2dhist=False  # boolean indicating whether to use 2D histogram to find initial offset, default=True\n",
    "\n",
    "pipe3=Image3Pipeline()    \n",
    "pipe3.tweakreg.kernel_fwhm = fwhm\n",
    "pipe3.tweakreg.snr_threshold = snr\n",
    "pipe3.tweakreg.minobj = minobj\n",
    "pipe3.tweakreg.sigma = sigma\n",
    "pipe3.tweakreg.fitgeometry = fit_geom\n",
    "pipe3.tweakreg.use2dhist = use2dhist\n",
    "pipe3.source_catalog.kernel_fwhm = fwhm\n",
    "pipe3.source_catalog.snr_threshold = snr\n",
    "pipe3.skymatch.save_results = True\n",
    "pipe3.outlier_detection.save_results = True\n",
    "pipe3.resample.save_results = True\n",
    "pipe3.source_catalog.save_results = True\n",
    "pipe3.save_results = True\n",
    "\n",
    "# run Image3\n",
    "pipe3.run('starfield_50star4ptdither_asnfile.json')    \n",
    "print('Image 3 pipeline finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"testing\"></a>\n",
    "# Perform Tests or Visualization\n",
    "\n",
    "View the image and check number of pixels being flagged as outliers. \n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in i2d file\n",
    "\n",
    "im_i2d = ImageModel('starfield_50star4ptdither_combined_i2d.fits')\n",
    "\n",
    "viz1 = LogStretch()\n",
    "viz2 = LogStretch() + ManualInterval(-5,5)\n",
    "norm = ImageNormalize(im_i2d.data, interval=MinMaxInterval(),\n",
    "                      stretch=LinearStretch())\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "#plt.imshow(viz2(im_i2d.data),cmap='gray')\n",
    "plt.imshow(im_i2d.data,origin='lower',norm=norm,vmin=-5, vmax=4)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image examination\n",
    "The image output should have the Four Quadrant phase masks on the left of the image masked out (values of 0). The image area should be smooth in the background regions with multiple point sources bright against the background. Passing criteria for the Lyot mask region are still being determined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check output of source catalog against image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photfile = 'starfield_50star4ptdither_combined_cat.ecsv'\n",
    "data = table.Table.read(photfile, format='ascii', comment='#')\n",
    "print(len(data),' sources detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in ecsv photom file\n",
    "from astropy.visualization import LogStretch, PercentileInterval, ManualInterval\n",
    "from astropy import table\n",
    "from matplotlib.colors import LogNorm\n",
    "from astropy.visualization import (MinMaxInterval, SqrtStretch,\n",
    "                                   ImageNormalize)\n",
    "\n",
    "viz1 = LogStretch()\n",
    "viz2 = LogStretch() + ManualInterval(-12,100)\n",
    "norm = ImageNormalize(im_i2d.data, interval=MinMaxInterval(),\n",
    "                      stretch=SqrtStretch())\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "#plt.imshow(viz2(im_i2d.data),cmap='gray')\n",
    "plt.imshow(im_i2d.data,origin='lower',norm=norm,vmin=-12, vmax=100)\n",
    "plt.colorbar()\n",
    "plt.scatter(data['xcentroid'], data['ycentroid'],lw=1, s=10,color='red')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check over source catalog match\n",
    "If the red dots marking sources found in image above are centered on the point sources, the test passes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check DQ Flagging of outlier detection \n",
    "Read in the individual crf files which are output from outlier_detection and check the dq extension to see how many pixels out of each image are flagged as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in each crf file output from outlier_detection and see percentage of pixels flagged as outlier\n",
    "outlierfiles = glob.glob('starfield*_crf.fits')\n",
    "\n",
    "flag_thresh = 1.0  # Percentage above which user should be notified of high percentage of flagged pixels\n",
    "\n",
    "for crffile in outlierfiles: \n",
    "    file = ImageModel(crffile)\n",
    "    nx = file.meta.subarray.xsize\n",
    "    ny = file.meta.subarray.ysize\n",
    "    filename = file.meta.filename\n",
    "    print(filename)\n",
    "\n",
    "    numpix = nx * ny\n",
    "    \n",
    "    # Test that all pixels flagged with OUTLIER are also flagged as DO_NOT_USE\n",
    "    outlierarray = (file.dq & dqflags.pixel['OUTLIER'] > 0)\n",
    "    badarray = (file.dq & dqflags.pixel['DO_NOT_USE'] > 0)\n",
    "    assert outlierarray.all() == badarray.all()\n",
    "    \n",
    "    # Count number of pixels flagged as OUTLIER\n",
    "    jumpcount = (file.dq & dqflags.pixel['OUTLIER'] > 0).sum()\n",
    "    print('There are ', jumpcount, ' pixels flagged as outliers.')\n",
    "    #print('Value of dq flag for pixel 784, 672: ', file.dq[672, 784])\n",
    "\n",
    "    percentflagged = (jumpcount / numpix) * 100.\n",
    "\n",
    "    print('The percentage of pixels flagged is ', percentflagged)\n",
    "    if percentflagged > flag_thresh:\n",
    "        print('This percentage is higher than it should be. Review data through outlier step')\n",
    "    print('\\n')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above should show percentages below some chosen threshold. If the percentage of pixels flagged as outliers are above the set threshold, there will be error messages printed. If no error messages are printed, this test is presumed to pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Author:** Misty Cracraft, Senior Staff Scientist, MIRI Branch\n",
    "<br>**Updated On:** 02/17/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<img style=\"float: right;\" src=\"./stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"stsci_pri_combo_mark_horizonal_white_bkgd\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
